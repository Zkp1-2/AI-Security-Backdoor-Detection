ğŸ” AI Model Poisoning & Backdoor Detection

A research project on adversarial poisoning attacks, stealth triggers, and model evaluation.

<p align="center"> <img src="https://img.shields.io/badge/PyTorch-Framework-red?style=for-the-badge"> <img src="https://img.shields.io/badge/MNIST-Dataset-yellow?style=for-the-badge"> <img src="https://img.shields.io/badge/Status-Completed-success?style=for-the-badge"> </p>
ğŸ“Œ Overview

This project explores backdoor attacks in deep learning models, where an attacker injects poisoned training samples containing a hidden trigger.
When the model is later exposed to this trigger, it misclassifies the input into the attackerâ€™s target label.

Your final implementation includes:

âœ”ï¸ Level 1 backdoor

âœ”ï¸ Level 2 blended trigger upgrade

âœ”ï¸ Poisoning ratios

âœ”ï¸ Model training pipeline

âœ”ï¸ Attack Success Rate (ASR) & Clean Accuracy evaluation

âœ”ï¸ Auto-generated backdoor report

âœ”ï¸ Saved backdoor model (upgraded_backdoor_cnn.pth)

ğŸ§  Key Concepts
ğŸ”¸ What is a Backdoor Attack?

A backdoor attack poisons a subset of the training dataset so that the model learns to associate a hidden trigger with a specific class.

ğŸ”¸ Blended Trigger (Level 2 Upgrade)

Instead of a visible patch, the trigger is blended into the image:

blended = (1 - Î±) * img + Î± * trigger


This makes the attack more stealthy and harder to detect.

ğŸ§ª Experimental Results (Î± = 0.35)
Poison Ratio	Clean Accuracy	ASR
0.01	97.86%	9.63%
0.03	97.99%	10.03%
0.05	99.00%	10.91%
0.10	98.31%	9.63%
0.15	97.95%	10.22%
ğŸ” Summary

Best Poison Ratio: 0.15

Max ASR: 10.91%

Accuracy Drop: extremely low (~0.017)

ğŸ§© Project Structure
```
AI-Security-Backdoor-Detection/
â”‚â”€â”€ notebooks/
â”‚   â”œâ”€â”€ 06_trigger_upgrade.ipynb
â”‚   â”œâ”€â”€ 07_report_generation.ipynb
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ MNIST/
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ backdoor_report.txt
â”‚
â”‚â”€â”€ upgraded_backdoor_cnn.pth
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore
```

ğŸš€ How to Run the Project
1ï¸âƒ£ Install dependencies
pip install torch torchvision matplotlib numpy

2ï¸âƒ£ Train backdoor model (Level 2)

Run:
```
notebooks/06_trigger_upgrade.ipynb
```
3ï¸âƒ£ Evaluate + generate report

Run:
```
notebooks/07_report_generation.ipynb

```
The final report will be saved automatically to:
```
/notebooks/reports/backdoor_report.txt
```
ğŸ¨ Visualization Example
Original	Blended Trigger (Î± = 0.35)
<img src="notebooks/images/original.png" width="130">	<img src="notebooks/images/blended.png" width="130">
ğŸ¤ Author

Phan Há»¯u ThÃ´ng (Zack)
Cyber Security â€” Griffith University
GitHub: https://github.com/Zkp1-2

â­ Enjoy the project?

Please consider starring â­ the repository â€” it helps a lot!
