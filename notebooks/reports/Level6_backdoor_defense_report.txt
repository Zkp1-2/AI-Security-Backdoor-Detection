==============================
LEVEL 6: Backdoor Defense via Fine-Pruning
==============================

Objective

To mitigate backdoor behavior by removing neurons associated with malicious activations.

Threat Model / Assumptions

Defender can modify the trained model.

No access to clean retraining data.

Methodology

Neurons with high activation variance for poisoned samples are pruned, followed by evaluation of attack suppression.

Experimental Setup

Dataset: MNIST

Model: Backdoored SimpleCNN

Defense: Fine-pruning

Results

ASR: Significantly reduced

Clean Accuracy: Recovered

Analysis

Fine-pruning effectively removes backdoor-related features while preserving clean performance.

Limitations

Not foolproof against adaptive or distributed triggers.

Conclusion

Fine-pruning is a practical, lightweight defense that demonstrates effective backdoor mitigation.

END OF LEVEL 6 REPORT
